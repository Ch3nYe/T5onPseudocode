import random
import warnings
from dataclasses import asdict
from multiprocessing import Pool, cpu_count
from os import truncate
from pathlib import Path
import datetime, time
import numpy as np
import pandas as pd
import torch
import re
import logging
import datasets
from datasets import load_dataset, load_metric
from torch.utils.tensorboard import SummaryWriter
from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler,BatchSampler
from torch.utils.data.distributed import DistributedSampler
from torch.nn.parallel import DistributedDataParallel
import torch.nn as nn
import gc
from tqdm.auto import tqdm, trange
import json
import math
import os
import random
from pathlib import Path
from time import time
import torch
from torch.utils.data import DataLoader
import transformers
import evaluate
from transformers import( 
                        RobertaTokenizerFast, 
                        LongT5ForConditionalGeneration,
                        LongT5Config,
                        T5Config,
                        T5ForConditionalGeneration, 
                        PreTrainedTokenizer,
)                         
from func_name_metric import get_aprf,my_split_func_name
from transformers.optimization import (
    get_constant_schedule,
    get_constant_schedule_with_warmup,
    get_linear_schedule_with_warmup,
    get_cosine_schedule_with_warmup,
    get_cosine_with_hard_restarts_schedule_with_warmup,
    get_polynomial_decay_schedule_with_warmup,
    AdafactorSchedule,
)
from torch.optim import AdamW
from transformers.optimization import Adafactor
from typing import Dict, List, Optional, Union
from transformers.utils import send_example_telemetry
from datasets import Dataset as HFDataset
from datasets import load_dataset,concatenate_datasets
try:
    import wandb

    wandb_available = True
except ImportError:
    wandb_available = False
from model.t5.t5_pretask import (
                        generate_MSP_dataset, 
                        SimilarityDataset, 
                        generate_SIP_dataset, 
                        generate_SUM_dataset,
)
from model.t5.config import T5Args
from model.t5.t5_utils import (load_hf_dataset, 
                       cmtimer,             
)
from evaluator import smooth_bleu
from evaluator.bleu import _bleu
from tqdm import tqdm, trange
from func_name_metric import get_aprf
from model.t5.t5_multi_task import (
                            DataCollatorForDataset,
                            T2TT5ModelForAccelerate
)
from evaluate.utils.file_utils import DownloadConfig
downlod_conf = DownloadConfig(proxies = {'http': '127.0.0.1:30000',
                                         "https":"127.0.0.1:30000",
                                         "socks5":"127.0.0.1:29999"})
from accelerate import Accelerator
from accelerate.logging import get_logger
from accelerate.utils import set_seed
from huggingface_hub import Repository
from accelerate.state import PartialState
from accelerate.utils import InitProcessGroupKwargs,GradScalerKwargs,DistributedDataParallelKwargs
static_graph_kwargs = DistributedDataParallelKwargs(static_graph=True)
state = PartialState()
import evaluate
MODEL_CLASSES = {
    "t5": (T5Config, T5ForConditionalGeneration),
    "longt5": (LongT5Config, LongT5ForConditionalGeneration),
}

task_to_keys = {
    "msp": ("src", "tgt"),
    "sip": ("src", "tgt"),
    "sum": ("src", "tgt"),
    "sim": ("src", None),
}

def default_collator (batch):
        [batch] = batch
        return batch

import evaluate



class DataCollatorForVarName(object):
    """Tokenize a batch of samples and generate mask for SIP sample.
    Args:
        tokenizer: A tokenizer.
        args: T5args.
        taskname: A dictionary of taskname and batch of samples.
    Call:
        task_batch: A batch generated by MultiTaskDataLoader.
    Returns:
        A dictionary of tokenized samples and mask.
    """
    def __init__(self, 
                 tokenizer : PreTrainedTokenizer,
                 args : T5Args,
                 taskname : str,
                 state : str,
                ) -> None:
        super(__class__,self).__init__()
        self.tokenizer = tokenizer
        self.name = taskname
        self.args = args
        self.eos_token_id = self.tokenizer.eos_token_id
        token_map = self.get_func_var_mapping(tokenizer,args)
        match_pattern = "|".join(token_map)
        match_pattern = "("+ match_pattern +")"
        self.x = re.compile(match_pattern)
        self.ukn_token_id = tokenizer.vocab["<ukn>"]
        self.state = state
        assert state in ["train","dev","test"]



    def get_func_var_mapping(self,tokenizer:RobertaTokenizerFast,args:T5Args):
            spec_token_map = []
            spec_token_map.append("<func>")
            for i in range(args.num_var_tokens):
                spec_token_map.append(f"<var_{i}>")
            for i in range(args.num_func_token - 1 , 0 , -1):
                spec_token_map.append(f'<func_{i}>')
            spec_token_map.append("</s>")
            spec_token_map.append("<s>")
            return spec_token_map 
    
    def split_var(self,example):
        res = self.x.split(example)
        var_dict = {}
        for ix,token in enumerate(res):
            if token.startswith("<var"):
                var_dict[token] = res[ix+1]
        return var_dict

    def __call__(self, batch: Dict[str,List[str]]):
        # [batch] = batch
        src = ["identifier_predict: " + item for item in batch["pcode"]] 

        tgt = ["<func>" + batch['name'][i] + batch['var_str'][i] for i in range(len(batch['name']))]
        model_input = self.tokenizer(
            text=src,
            max_length=self.args.max_src_length,
            padding="max_length",
            return_tensors="pt",
            truncation=True,
            pad_to_multiple_of = 8 if self.args.fp16 else None,
        )
        labels = self.tokenizer(
            text=tgt,
            max_length=self.args.max_tgt_length,
            padding="max_length",
            return_tensors="pt",
            truncation=True, 
            pad_to_multiple_of = 8 if self.args.fp16 else None,
        )
        model_input["labels"] = labels["input_ids"]
        model_input['labels'][model_input['labels'] == self.ukn_token_id] =  -100
        # lable must be -100 for padding
        # https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5Tokenizer
        model_input['labels'][model_input['labels'] == self.tokenizer.pad_token_id] = -100
        if self.state == "test" or self.state == "dev":
            model_input['on_train'] = batch['test_meta']
        return model_input
    



def init_base_component(cmd_args: T5Args):
    args = cmd_args
    accelerator = (
        Accelerator(
                    log_with=args.report_to, 
                    project_dir=args.output_dir,
                   ) if args.with_tracking else Accelerator(project_dir=args.output_dir,)
    )
    logging.basicConfig(
            format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
            datefmt="%m/%d/%Y %H:%M:%S",
            level=logging.INFO,
    )
    logger.info(accelerator.state, main_process_only=True)
    send_example_telemetry("run_pretrain_tasks_t5_pcode", args)
    # set seed and model
    if not args.output_dir:
        args.output_dir = args.model_name + f"{random.randint(0, 100000)}"
        logger.warning(f"output_dir not specified, using {args.output_dir}")
    if args.manual_seed is not None:
        set_seed(args.manual_seed,args.device_specific)
    config_class, model_class = MODEL_CLASSES[args.model_type]
    if args.model_name is None:
        logger.error("Must Specify a model name")
        exit(1)
    else:
        config = config_class.from_pretrained(args.model_name, **args.config)
        model = model_class.from_pretrained(args.model_name, config=config)
    # change the model to the correct vocab size
    if args.tokenizer_path is None:
        logger.error("Must Specify a tokenizer path")
        exit(1)
    tokenizer = RobertaTokenizerFast.from_pretrained(args.tokenizer_path)
    if args.special_tokens_list:
        tokenizer.add_tokens(
            args.special_tokens_list, special_tokens=True
        )

    embedding_size = model.get_input_embeddings().weight.shape[0]
    if len(tokenizer) > embedding_size:
        model.resize_token_embeddings(len(tokenizer))

    if accelerator.is_main_process:
        datasets.utils.logging.set_verbosity_warning()
        transformers.utils.logging.set_verbosity_info()
        os.makedirs(args.output_dir, exist_ok=True)
    else:
        datasets.utils.logging.set_verbosity_error()
        transformers.utils.logging.set_verbosity_error()

    return args, accelerator, tokenizer, model

logger = get_logger(__name__)


def default_collator (batch):
        [batch] = batch
        return batch



def init_dataloader(seed,dataset,tokenizer,args,batch_size,state):
    data_collator = DataCollatorForVarName(tokenizer, args, "sip",state=state)
    dataset = dataset.shuffle(seed)
    dataset = dataset.map(data_collator, batched=True, num_proc=8, batch_size=100, remove_columns=dataset.column_names)
    dataset.set_format('pt')
    dataset = dataset.filter(lambda x: torch.sum(x['input_ids'].ne(tokenizer.pad_token_id)) > args.ignore_minimum_length)
    # batch_sampler = BatchSampler(SequentialSampler(dataset), batch_size=batch_size, drop_last=args.drop_last)
    batch_sampler = BatchSampler(RandomSampler(dataset), batch_size=batch_size, drop_last=args.drop_last)
    dataloader = DataLoader(dataset,
                            sampler=batch_sampler,
                            collate_fn=default_collator,
                            pin_memory=args.pin_memory,
                            num_workers=args.num_workers,)
    dataloader = accelerator.prepare(dataloader)
    return dataloader


def init_dataset_concat(args: T5Args, tokenizer, accelerator,batch_size,seed=2402,path=""):
    dataset = datasets.load_dataset("./dire_dataset")
    train_dataset = dataset["train"]
    val_dataset = dataset["test"]
    train_loader = init_dataloader(seed,train_dataset,tokenizer,args,batch_size,"train")
    val_loader = init_dataloader(seed,val_dataset,tokenizer,args,batch_size,"dev")
    return train_loader,val_loader


def load_training_checkpoint(model, load_dir, tag=None, **kwargs):
    """Utility function for checkpointing model + optimizer dictionaries
    The main purpose for this is to be able to resume training from that instant again
    """
    _, checkpoint_state_dict = model.load_checkpoint(load_dir, tag=tag, **kwargs)
    epoch = checkpoint_state_dict["epoch"]
    last_global_step = checkpoint_state_dict["last_global_step"]
    init_epoch = checkpoint_state_dict["init_epoch_msp"]
    del checkpoint_state_dict
    return (epoch, last_global_step,init_epoch)

def checkpoint_model(checkpoint_folder, ckpt_id, model, epoch, last_global_step, **kwargs):
    """Utility function for checkpointing model + optimizer dictionaries
    The main purpose for this is to be able to resume training from that instant again
    """
    init_epoch = kwargs.pop("init_epoch", None)
    checkpoint_state_dict = {
        "epoch": epoch,
        "last_global_step": last_global_step,
        "init_epoch_msp": init_epoch,
    }
    # Add extra kwargs too
    checkpoint_state_dict.update(kwargs)

    success = model.save_checkpoint(checkpoint_folder, ckpt_id, checkpoint_state_dict)
    status_msg = f"checkpointing: checkpoint_folder={checkpoint_folder}, ckpt_id={ckpt_id}"
    if success:
        logging.info(f"Success {status_msg}")
    else:
        logging.warning(f"Failure {status_msg}")
    return


def init_optimizer_scheduler(args:T5Args, model, accelerator, num_train_steps_per_epoch):
    # init the optimizer and scheduler
    no_decay = ["bias", "LayerNorm.weight","layer_norm.weight"]
    optimizer_grouped_parameters = []
    custom_parameter_names = set()
    for group in args.custom_parameter_groups:
        params = group.pop("params")
        custom_parameter_names.update(params)
        param_group = {**group}
        param_group["params"] = [
            p for n, p in model.named_parameters() if n in params
        ]
        optimizer_grouped_parameters.append(param_group)

    for group in args.custom_layer_parameters:
        layer_number = group.pop("layer")
        layer = f"layer.{layer_number}."
        group_d = {**group}
        group_nd = {**group}
        group_nd["weight_decay"] = 0.0
        params_d = []
        params_nd = []
        for n, p in model.named_parameters():
            if n not in custom_parameter_names and layer in n:
                if any(nd in n for nd in no_decay):
                    params_nd.append(p)
                else:
                    params_d.append(p)
                custom_parameter_names.add(n)
        group_d["params"] = params_d
        group_nd["params"] = params_nd
        optimizer_grouped_parameters.append(group_d)
        optimizer_grouped_parameters.append(group_nd)

    if not args.train_custom_parameters_only:
        optimizer_grouped_parameters.extend(
            [
                {
                    "params": [
                        p
                        for n, p in model.named_parameters()
                        if n not in custom_parameter_names
                        and not any(nd in n for nd in no_decay)
                    ],
                    "weight_decay": args.weight_decay,
                },
                {
                    "params": [
                        p
                        for n, p in model.named_parameters()
                        if n not in custom_parameter_names
                        and any(nd in n for nd in no_decay)
                    ],
                    "weight_decay": 0.0,
                },
            ]
        )
    
    args.num_update_steps_per_epoch = math.ceil( num_train_steps_per_epoch / args.gradient_accumulation_steps)
    if args.max_steps > 0:
        total_step = args.max_steps
        args.num_train_epochs = (
             math.ceil(args.max_train_steps / args.num_update_steps_per_epoch)
        )
    else:
        total_step = (
            args.num_train_epochs * args.num_update_steps_per_epoch
        )
    args.total_step = total_step
    warmup_steps = math.ceil(total_step * args.warmup_ratio)
    args.warmup_steps = (
        warmup_steps if args.warmup_steps == 0 else args.warmup_steps
    )
    if accelerator.state.deepspeed_plugin is None or "optimizer" not in accelerator.state.deepspeed_plugin.deepspeed_config:
        if args.optimizer == "AdamW":
            optimizer = AdamW(
                optimizer_grouped_parameters,
                lr=args.learning_rate,
                eps=args.adam_epsilon,
                betas=args.adam_betas,
            )
        elif args.optimizer == "Adafactor":
            optimizer = Adafactor(
                optimizer_grouped_parameters,
                lr=args.learning_rate,
                eps=args.adafactor_eps,
                clip_threshold=args.adafactor_clip_threshold,
                decay_rate=args.adafactor_decay_rate,
                beta1=args.adafactor_beta1,
                weight_decay=args.weight_decay,
                scale_parameter=args.adafactor_scale_parameter,
                relative_step=args.adafactor_relative_step,
                warmup_init=args.adafactor_warmup_init,
            )

        else:
            raise ValueError(
                "{} is not a valid optimizer class. Please use one of ('AdamW', 'Adafactor') instead.".format(
                    args.optimizer
                )
            )
    else:
        import accelerate
        optimizer = accelerate.utils.DummyOptim(optimizer_grouped_parameters, 
                                                lr=args.learning_rate)
    if  accelerator.state.deepspeed_plugin is None or \
          "scheduler" not in accelerator.state.deepspeed_plugin.deepspeed_config:
        if args.scheduler == "constant_schedule":
            scheduler = get_constant_schedule(optimizer)

        elif args.scheduler == "constant_schedule_with_warmup":
            scheduler = get_constant_schedule_with_warmup(
                optimizer, num_warmup_steps=args.warmup_steps
            )

        elif args.scheduler == "linear_schedule_with_warmup":
            scheduler = get_linear_schedule_with_warmup(
                optimizer,
                num_warmup_steps=args.warmup_steps,
                num_training_steps=total_step,
            )

        elif args.scheduler == "cosine_schedule_with_warmup":
            scheduler = get_cosine_schedule_with_warmup(
                optimizer,
                num_warmup_steps=args.warmup_steps,
                num_training_steps=total_step,
                num_cycles=args.cosine_schedule_num_cycles,
            )

        elif args.scheduler == "cosine_with_hard_restarts_schedule_with_warmup":
            scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(
                optimizer,
                num_warmup_steps=args.warmup_steps,
                num_training_steps=total_step,
                num_cycles=args.cosine_schedule_num_cycles,
            )

        elif args.scheduler == "polynomial_decay_schedule_with_warmup":
            scheduler = get_polynomial_decay_schedule_with_warmup(
                optimizer,
                num_warmup_steps=args.warmup_steps,
                num_training_steps=total_step,
                lr_end=args.polynomial_decay_schedule_lr_end,
                power=args.polynomial_decay_schedule_power,
            )

        elif args.adafactor_warmup_init is False:
            scheduler = AdafactorSchedule(optimizer)

        else:
            raise ValueError("{} is not a valid scheduler.".format(args.scheduler))
    else:
        from accelerate.utils import DummyScheduler
        scheduler = DummyScheduler(
            optimizer, total_num_steps=args.total_step, warmup_num_steps=args.warmup_steps
        )    
    return optimizer, scheduler


def eval_var_name(args, model:T5ForConditionalGeneration, 
                  tokenizer:RobertaTokenizerFast, 
                  accelerator,eval_dataloader,current_epoch):
    gen_kwargs = {
        "max_length": 192,
        "num_beams": 4,
        "min_length": 4,
        "length_penalty": 1.0,
        "no_repeat_ngram_size": 3,
        "encoder_no_repeat_ngram_size": 3,
        "repetition_penalty": 1.2,
        "early_stopping" :False, 
    }
    model.eval()   
    # eval sum first
    batch_iterator = tqdm(
            eval_dataloader,
            desc=f"EVAL Epoch {current_epoch} of {args.num_train_epochs}: SIP",
            disable=args.silent or not accelerator.is_local_main_process,
            mininterval=0,
    )
    cer_metric = evaluate.load('cer',download_config=downlod_conf)
    samples_seen = 0
    accelerator.wait_for_everyone()
    preds = []
    refers = []
    on_trains = []
    for step, batch in enumerate(batch_iterator):
        if step  == 100 :
            break
        with torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch["input_ids"],
                attention_mask=batch["attention_mask"],
                **gen_kwargs,
            )

            generated_tokens = accelerator.pad_across_processes(
                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id
            )
            labels = batch["labels"]
            on_train = batch["on_train"]
            labels = accelerator.pad_across_processes(batch["labels"], dim=1, pad_index=tokenizer.pad_token_id)
            generated_tokens, labels, on_train = \
                accelerator.gather_for_metrics((generated_tokens, labels, on_train))
            generated_tokens = generated_tokens.cpu().numpy()
            labels = labels.masked_fill_(labels == -100, tokenizer.pad_token_id)
            on_train = on_train.cpu()
            labels = labels.cpu().numpy()               
            if isinstance(generated_tokens, tuple):
                generated_tokens = generated_tokens[0]
            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)
            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=False)
            preds += decoded_preds
            refers += decoded_labels
            on_trains += on_train   
                
            if accelerator.num_processes > 1:
                if step == len(eval_dataloader) - 1:
                    decoded_preds = decoded_preds[: len(eval_dataloader.dataset) - samples_seen]
                    decoded_labels = decoded_labels[: len(eval_dataloader.dataset) - samples_seen]
                else:
                    samples_seen += len(decoded_labels)

    data_collator = DataCollatorForVarName(tokenizer, args, "var_name","dev")
    in_train_refers = []
    in_train_preds = []
    in_train_cnt = 0
    in_train_acc = 0
    out_train_cnt = 0
    out_train_acc = 0
    out_train_refers = []
    out_train_preds = []
    for i in trange(len(preds)):
        var_pred_dict = data_collator.split_var(preds[i])
        var_refers_dict = data_collator.split_var(refers[i])
        body_on_train = on_trains[i]
        for key,value in var_refers_dict.items():
            pred = var_pred_dict.get(key,"default")
            refer = value
            if value == "<pad>": #"<ukn>"
                continue
            if body_on_train:
                if pred == refer:
                    in_train_acc += 1
                in_train_cnt += 1
                in_train_preds.append(pred)
                in_train_refers.append(refer)
            else:
                if pred == refer:
                    out_train_acc += 1
                out_train_cnt += 1
                out_train_preds.append(pred)
                out_train_refers.append(refer)
    in_cer_score = cer_metric.compute(predictions=in_train_preds, references=in_train_refers)
    out_cer_score = cer_metric.compute(predictions=out_train_preds, references=out_train_refers)
    all_var_refers = in_train_refers + out_train_refers
    all_var_preds = in_train_preds + out_train_preds
    all_cer_score = cer_metric.compute(predictions=all_var_preds, references=all_var_refers)
    result_dir = os.path.join(args.output_dir,"eval_tmp")
    os.makedirs(result_dir,exist_ok=True)
    refer_fn = os.path.join(result_dir, f"eval_{current_epoch}_var.refer.txt")
    pred_fn = os.path.join(result_dir, f"eval_{current_epoch}_var.pred.txt")
    with open(refer_fn,"w") as f:
        f.write("\n".join(all_var_refers))
    with open(pred_fn,"w") as f:
        f.write("\n".join(all_var_preds))
    result = {"all cer":all_cer_score,
              "all top1 acc":(in_train_acc+out_train_acc)/(in_train_cnt+out_train_cnt),
              "body in train cer":in_cer_score,
              "top-1 acc in train": in_train_acc/in_train_cnt, 
              "body not in train cer":out_cer_score,
              "top-1 acc not in train": out_train_acc/out_train_cnt }
    result = {k: round(v * 100, 4 ) for k, v in result.items()}
    return result

def finetune(args:T5Args, accelerator, model, tokenizer, optimizer, scheduler,
          train_loader, dev_loader):
    """ Train the model """
    # model = T2TT5ModelForAccelerate(model)
    model,optimizer,scheduler= accelerator.prepare(model,optimizer,scheduler)

    args.total_steps = args.num_train_epochs * args.num_update_steps_per_epoch
 
    # Figure out how many steps we should save the Accelerator states
    total_t2t_batch_size = args.per_device_train_batch_size * \
        accelerator.num_processes * args.gradient_accumulation_steps
    
    epoch = 0
    completed_steps = 0
    starting_epoch = 0
    if args.resume_from_checkpoint != "" and args.resume_from_checkpoint is not None:
        # New Code #
        # Loads the DeepSpeed checkpoint from the specified path
        _, last_global_step, init_epoch = load_training_checkpoint(
            model,
            args.resume_from_checkpoint,
            **{"load_optimizer_states": True, "load_lr_scheduler_states": True},
        )
        accelerator.print(f"Resumed from checkpoint: {args.resume_from_checkpoint}")
        completed_steps = last_global_step
        resume_step = last_global_step
        starting_epoch = resume_step // len(train_loader)
        resume_step -= starting_epoch * len(train_loader)


    if args.with_tracking:
        experiment_config = vars(args)
        accelerator.init_trackers(args.wandb_project, \
                                  experiment_config,init_kwargs={"wandb":{"entity":args.wandb_entity}})

    logger.info("***** Running training *****")
    logger.info(f"  Num examples = {len(train_loader)}")
    logger.info(f"  Num Epochs = {args.num_train_epochs}")
    logger.info(f"  Current Epoch = {starting_epoch}")
    logger.info(f"  Instantaneous batch size per device = {args.per_device_train_batch_size}")
    logger.info(f"  Gradient Accumulation steps = {args.gradient_accumulation_steps}")
    logger.info(f"  Total train batch size (w. parallel, distributed & accumulation) = {total_t2t_batch_size}")
    logger.info(f"  Total optimization steps = {args.total_step}")
    if args.resume_from_checkpoint:
        logger.info(f"  Resume step = {resume_step}")
        logger.info(f"  Starting epoch = {starting_epoch}")

    total_results = {}
    total_loss = 0
    for current_epoch in range(starting_epoch, args.num_train_epochs):
        task_type = "var recovery"
        model.train()
        if current_epoch == starting_epoch:
            total_loss = 0
        batch_iterator = tqdm(
            train_loader,
            desc=f"Running Epoch {current_epoch} of {args.num_train_epochs}: {task_type}  tasks",
            disable=args.silent or not accelerator.is_local_main_process,
            mininterval=0,
        )
        for step, batch in enumerate(batch_iterator):
            if args.eval_only:
                break
            loss = model(**batch).loss
            if args.with_tracking:
                total_loss += loss.item()
            loss = loss / args.gradient_accumulation_steps
            accelerator.backward(loss)
            if step % args.gradient_accumulation_steps == 0 or \
                step == args.num_update_steps_per_epoch - 1:
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
                completed_steps += 1

            if args.debug and completed_steps % args.wandb_logging_steps == 0 and args.with_tracking and step != 0:
                train_loss = total_loss / completed_steps 
                accelerator.log(
                        {
                            "train_loss": train_loss,
                        },
                        step=completed_steps,
                )
            
            if completed_steps >= args.total_step:
                break

            if step % args.checkpointing_steps == 0 and step != 0:
                    checkpoint_model(args.output_dir,completed_steps, model, current_epoch, 
                                     completed_steps, init_epoch=0)
        if not args.eval_only:       

            checkpoint_model(args.output_dir, completed_steps, model,
                            current_epoch, completed_steps, init_epoch=0)

        accelerator.wait_for_everyone()

        result = eval_var_name(args,model,tokenizer,accelerator,dev_loader,current_epoch)
        logger.info(result)
        if args.with_tracking:
            result["train_loss"] = total_loss / completed_steps
            result["epoch"] = current_epoch
            result["step"] = completed_steps
            accelerator.log(result, step=completed_steps)
        
        total_results[current_epoch] = result
        

    # unwrapped_model = accelerator.unwrap_model(model).get_model()
    unwrapped_model = accelerator.unwrap_model(model)
    os.makedirs(os.path.join(args.output_dir,f"{current_epoch}"),exist_ok=True)
    unwrapped_model.save_pretrained(
        os.path.join(args.output_dir,f"{current_epoch}"), 
        is_main_process=accelerator.is_main_process, 
        save_function=accelerator.save,
        state_dict=accelerator.get_state_dict(unwrapped_model,unwrap=False)
    )
    if accelerator.is_main_process:
        total_results = {f"eval_{k}": v for k, v in total_results.items()}
        with open(os.path.join(args.output_dir,f"{current_epoch}",f"{args.task_type}_results.json"), "w+") as f:
            json.dump(total_results, f)
    


if __name__ == "__main__":
    from simple_parsing import ArgumentParser
    parser = ArgumentParser()
    parser.add_arguments(T5Args, dest="t5_args")
    cmd_args = parser.parse_args().t5_args
    args,accelerator,tokenzier,model = init_base_component(cmd_args)
    train_loader, dev_loader = init_dataset_concat(args,tokenzier,accelerator,batch_size= args.per_device_eval_batch_size,seed=args.manual_seed)
    optimizer, scheduler = init_optimizer_scheduler(args,model,accelerator,len(train_loader))
    finetune(args,accelerator,model,tokenzier,optimizer,scheduler,train_loader,dev_loader)
    